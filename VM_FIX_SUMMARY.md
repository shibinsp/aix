# VM Startup Issue - Fixed! âœ…

## Issue Summary

The error "Failed to start VM. Please try again." was caused by a database schema mismatch. The application code referenced a column `terminated_by_admin` that didn't exist in the database.

## Root Cause

The `lab_sessions` table was missing the `terminated_by_admin` column which was added to the model but never migrated to the database.

## Fix Applied

Added the missing column to the database:
```sql
ALTER TABLE lab_sessions ADD COLUMN IF NOT EXISTS terminated_by_admin BOOLEAN DEFAULT false;
```

## Test Results

All VM/Lab functionality is now working correctly:

```
âœ… Authentication: Working
âœ… Backend Health: Healthy
âœ… VM Presets: Available (minimal, server, developer, desktop, desktop-kali)
âœ… Docker Images: Available
âœ… VM Start: Successfully creates container
âœ… Container Running: Verified
âœ… VM Stop: Clean shutdown
âœ… Cleanup: Container removed properly
```

## Test Script

Created comprehensive test script: `/root/AI_CyberX/test_vm.sh`

Run it anytime to verify VM functionality:
```bash
cd /root/AI_CyberX
./test_vm.sh
```

## How the VM System Works

The "VM" feature actually uses **Docker containers** that provide VM-like environments, not actual QEMU/KVM virtual machines.

### Available Presets

1. **Minimal** - Alpine Linux CLI (~400MB)
   - SSH access
   - Basic tools: curl, wget, htop
   
2. **Server** - Server tools (~600MB)
   - SSH, tmux, git
   - Network tools: nmap, tcpdump, iptables

3. **Developer** - Development environment (~1.5GB)
   - Python3, GCC, GDB, Docker
   - Security tools: pwntools

4. **Desktop** - Ubuntu XFCE GUI (~2GB)
   - VNC/noVNC access
   - Firefox browser, file manager
   - Terminal and tools

5. **Desktop-Kali** - Kali Linux Desktop (~3GB)
   - Full Kali Linux environment
   - Security tools: nmap, Metasploit, Burp Suite, Wireshark

### Architecture

```
User Request (Frontend)
    â†“
API: POST /api/v1/labs/alphha/start?preset=minimal
    â†“
Lab Manager: start_alphha_linux_lab()
    â†“
Docker Container Created:
  - Image: alpine:latest (or cyberlab-vm:latest)
  - Ports: Random SSH port (e.g., 12605)
  - Network: Isolated Docker network
  - Labels: cyberx.session=<session_id>
    â†“
Session Stored in Database:
  - session_id
  - user_id  
  - status: running
  - ssh_port
  - expires_at (120 minutes default)
    â†“
Response to User:
  - SSH access details
  - Port number
  - Credentials (username: alphha, password: alphha)
```

## API Endpoints

### Start VM
```bash
POST /api/v1/labs/alphha/start?preset=minimal
Authorization: Bearer <token>

Response:
{
  "session_id": "...",
  "status": "running",
  "ssh_port": 12605,
  "credentials": {
    "username": "alphha",
    "password": "alphha"
  }
}
```

### Stop VM
```bash
POST /api/v1/labs/sessions/{session_id}/stop
Authorization: Bearer <token>

Response:
{
  "message": "Lab session stopped"
}
```

### List Active Sessions
```bash
GET /api/v1/labs/sessions/my
Authorization: Bearer <token>

Response: [
  {
    "id": "...",
    "status": "running",
    "ssh_port": 12605,
    "expires_at": "..."
  }
]
```

### Get Presets
```bash
GET /api/v1/labs/alphha/presets
Authorization: Bearer <token>
```

### Check Available Images
```bash
GET /api/v1/labs/alphha/images
Authorization: Bearer <token>
```

## Container Management

All lab containers are automatically:
- Tagged with `cyberx.session=<session_id>` label
- Connected to isolated Docker network
- Given random SSH/VNC ports to avoid conflicts
- Set to expire after 120 minutes (configurable)
- Cleaned up when stopped

### Manual Container Check
```bash
# List all lab containers
docker ps --filter "label=cyberx.session"

# Check specific session
docker ps --filter "label=cyberx.session=<session_id>"

# View logs
docker logs cyberx_<session_id>_target

# Manual cleanup (if needed)
docker stop cyberx_<session_id>_target
docker rm cyberx_<session_id>_target
```

## Configuration

Lab settings in environment variables:
```env
LAB_TIMEOUT_MINUTES=120          # Default session duration
MAX_CONCURRENT_LABS=50           # Maximum simultaneous labs
```

## Frontend Integration

The frontend `/vm` page:
1. Calls `vmApi.startVM(preset)` 
2. Shows loading state
3. On success: Displays terminal/desktop interface
4. On error: Shows "Failed to start VM" message

The error was happening because the API was failing due to the database column issue, not because of VM/container problems.

## Troubleshooting

If you encounter VM issues:

1. **Check backend logs:**
   ```bash
   docker logs cyberx-backend --tail 100
   ```

2. **Run test script:**
   ```bash
   /root/AI_CyberX/test_vm.sh
   ```

3. **Check Docker availability in container:**
   ```bash
   docker exec cyberx-backend docker ps
   ```

4. **Verify images:**
   ```bash
   docker images | grep -E "alpine|cyberlab-vm"
   ```

5. **Check database column:**
   ```bash
   docker exec cyberx-postgres psql -U cyberx -d cyberx -c "\d lab_sessions"
   ```

## Future Improvements

1. **Custom Alphha Linux Images**: Build custom images with pre-installed tools
2. **Warm VM Pool**: Pre-start VMs for faster access
3. **Snapshots**: Save/restore VM states
4. **Real QEMU/KVM**: Optional real VMs for kernel-level work
5. **GPU Access**: Pass-through GPU for graphics-intensive labs

## Verification

âœ… Database schema fixed  
âœ… VM start/stop working  
âœ… Container isolation working  
âœ… Port mapping working  
âœ… Session management working  
âœ… Cleanup working  
âœ… All presets available  
âœ… Comprehensive test script created

## Summary

The VM functionality is now **fully operational**. The issue was a simple database schema mismatch that has been resolved. Users can now successfully:

- Start VM environments (minimal, server, developer, desktop)
- Access via SSH or VNC
- Run cybersecurity labs
- Stop and cleanup sessions

All systems tested and verified working! ðŸŽ‰
